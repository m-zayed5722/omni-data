version: '3.8'

services:
  ai-agent-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      - OLLAMA_MODEL=mistral
      - TAVILY_API_KEY=${TAVILY_API_KEY}
      - OPENWEATHER_API_KEY=${OPENWEATHER_API_KEY}
      - SERP_API_KEY=${SERP_API_KEY}
    volumes:
      - ./.env:/app/.env
      - ./uploads:/app/uploads
    depends_on:
      - ollama
    restart: unless-stopped
    command: ["uvicorn", "app.main_viz:app", "--host", "0.0.0.0", "--port", "8000"]

  streamlit-frontend:
    build: .
    ports:
      - "8501:8501"
    environment:
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      - OLLAMA_MODEL=mistral
    volumes:
      - ./.env:/app/.env
    depends_on:
      - ai-agent-api
    restart: unless-stopped
    command: ["streamlit", "run", "frontend/streamlit_app.py", "--server.port=8501", "--server.address=0.0.0.0"]

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped

volumes:
  ollama_data: